{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":108376,"databundleVersionId":13345061,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"execution_failed":"2025-08-13T13:44:10.531Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#All the necessary imports\nimport os, gc, warnings\nfrom pathlib import Path\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import TimeSeriesSplit\nfrom sklearn.metrics import mean_squared_error\nfrom scipy.stats import pearsonr\nimport lightgbm as lgb\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models, callbacks\n\n#Ignoring the warnings \nwarnings.filterwarnings('ignore')\npd.set_option('display.max_columns', 200)\nsns.set_style('darkgrid')\n\n#initialising SEED value as 42\nSEED = 42\nnp.random.seed(SEED)\ntf.random.set_seed(SEED)\n\n#This is the base path of the project ie. the root directory\nBASE_PATH = \"/kaggle/input/gq-implied-volatility-forecasting\"   \nTRAIN_DIR = os.path.join(BASE_PATH, \"train\")\nTEST_DIR  = os.path.join(BASE_PATH, \"test\")\nOUT_DIR = \"/kaggle/working/submissions\"\nos.makedirs(OUT_DIR, exist_ok=True)\n\nLABEL_FILE = None\n\n#Initialising the sequence length,lstm epochs, batch size, TSCV splits and Holdout seconds\nSEQ_LEN = 60         \nLSTM_EPOCHS = 8     \nBATCH_SIZE = 128\nTSCV_SPLITS = 5\nHOLDOUT_SECONDS = 3600","metadata":{"trusted":true,"execution":{"execution_failed":"2025-08-13T13:44:10.531Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Checking whether the base path exists\nprint(\"BASE_PATH exists:\", Path(BASE_PATH).exists())\ntrain_files = sorted([f for f in os.listdir(TRAIN_DIR) if f.lower().endswith('.csv')]) if Path(TRAIN_DIR).exists() else []\ntest_files  = sorted([f for f in os.listdir(TEST_DIR)  if f.lower().endswith('.csv')]) if Path(TEST_DIR).exists() else []\n\nprint(\"train files:\", train_files)\nprint(\"test files: \", test_files)\ncoins = [os.path.splitext(f)[0] for f in train_files]\nprint(\"coins:\", coins)\n\nlabel_candidates = []\n\n#Checking if the path exists then append to the label_candidates list\nif LABEL_FILE and Path(LABEL_FILE).exists():\n    label_candidates.append(LABEL_FILE)\nelse:\n    for name in ['train_labels.csv','train_iv_labels.csv','labels.csv','submission.csv','train_labels_10s.csv']:\n        p = os.path.join(BASE_PATH, name)\n        if Path(p).exists():\n            label_candidates.append(p)\n            \n#Reading the CSV files if they exist in the label_candidates list         \nif label_candidates:\n    LABEL_PATH = label_candidates[0]\n    print(\"Using label file:\", LABEL_PATH)\n    global_labels = pd.read_csv(LABEL_PATH, parse_dates=['timestamp'], low_memory=False)\nelse:\n    LABEL_PATH = None\n    global_labels = None\n    print(\"No global label file found. Models will expect iv column in train CSVs.\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-08-13T13:44:10.531Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n#These are the train and test directories\nTRAIN_DIR = \"/kaggle/input/gq-implied-volatility-forecasting/train\"\nTEST_DIR = \"/kaggle/input/gq-implied-volatility-forecasting/test\"\n\ncoins = sorted([f.replace('.csv','') for f in os.listdir(TRAIN_DIR) if f.endswith('.csv')])\n\n#performing EDA(exploratory data analysis)\ndef eda_for_coin(coin):\n    print(f\"\\n--- EDA for coin: {coin} ---\")\n    train_path = os.path.join(TRAIN_DIR, f\"{coin}.csv\")\n    test_path = os.path.join(TEST_DIR, f\"{coin}.csv\")\n    \n    #Reading the csv files inside the train and test\n    df_train = pd.read_csv(train_path)\n    df_test = pd.read_csv(test_path)\n    \n    print(f\"Train shape: {df_train.shape}, Test shape: {df_test.shape}\")\n    print(\"Train columns:\", df_train.columns.tolist())\n    print(\"Missing values (train):\\n\", df_train.isnull().sum())\n    print(\"Missing values (test):\\n\", df_test.isnull().sum())\n    \n    #Describing the train and test datasets\n    print(\"Train describe:\\n\", df_train.describe())\n    print(\"Test describe:\\n\", df_test.describe())\n    \n    #Converting timestamp to datetime feature\n    df_train['timestamp'] = pd.to_datetime(df_train['timestamp'], errors='coerce')\n    df_test['timestamp'] = pd.to_datetime(df_test['timestamp'], errors='coerce')\n\n    #Plotting the figures with timestamp, mid_price etc.\n    plt.figure(figsize=(12,4))\n    plt.plot(df_train['timestamp'].iloc[::max(1,len(df_train)//1000)], \n             df_train['mid_price'].iloc[::max(1,len(df_train)//1000)], label='Train mid_price')\n    plt.plot(df_test['timestamp'].iloc[::max(1,len(df_test)//1000)], \n             df_test['mid_price'].iloc[::max(1,len(df_test)//1000)], label='Test mid_price')\n    plt.title(f\"{coin} mid_price over time\")\n    plt.xlabel(\"Timestamp\")\n    plt.ylabel(\"Mid Price\")\n    plt.legend()\n    plt.show()\n    \n#Repeating the process for all coins(BTC,ETH,SHIB etc.)\nfor coin in coins:\n    eda_for_coin(coin)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-08-13T13:44:10.531Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\n#Initialising the submission path\nSUBMISSION_PATH = \"/kaggle/input/gq-implied-volatility-forecasting/submission.csv\"\n\n#Reading the submission path which contains timestamp and labels\nglobal_labels = pd.read_csv(SUBMISSION_PATH)\nglobal_labels['timestamp'] = pd.to_datetime(global_labels['timestamp'], errors='coerce')\nglobal_labels = global_labels.dropna(subset=['timestamp']).reset_index(drop=True)\n\n#printing the global_labels sample\nprint(\"Loaded global_labels sample:\")\nprint(global_labels.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T14:17:28.273544Z","iopub.execute_input":"2025-08-15T14:17:28.273960Z","iopub.status.idle":"2025-08-15T14:17:28.879764Z","shell.execute_reply.started":"2025-08-15T14:17:28.273926Z","shell.execute_reply":"2025-08-15T14:17:28.878592Z"}},"outputs":[{"name":"stdout","text":"Loaded global_labels sample:\n                      timestamp    labels\n0 1970-01-01 00:00:00.000000001  0.381921\n1 1970-01-01 00:00:00.000000002  0.590922\n2 1970-01-01 00:00:00.000000003  0.663046\n3 1970-01-01 00:00:00.000000004  0.954191\n4 1970-01-01 00:00:00.000000005  0.091550\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import numpy as np\n\n#Feature engineering step\ndef feature_engineering_coin(df, global_labels):\n    \n    #Creates a safe copy of the Dataframe\n    df = df.copy()\n    df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')\n    \n    #Dropping the rows where timestamp failed to convert\n    df = df.dropna(subset=['timestamp']).reset_index(drop=True)\n\n    df = df.sort_values('timestamp').reset_index(drop=True)\n\n    df['time_10s'] = df['timestamp'].dt.floor('10S')\n    \n    #Group each row by 10s and in each 10s window calculates open,high,low and close\n    ohlcv = df.groupby('time_10s')['mid_price'].agg(\n        open='first', high='max', low='min', close='last').reset_index()\n    \n    #Calculates bid_volume1 to bid_volume4 along with total bid_volume per row and group by 10s\n    bid_volume_cols = [f'bid_volume{i}' for i in range(1,5) if f'bid_volume{i}' in df.columns]\n    df['total_bid_volume'] = df[bid_volume_cols].sum(axis=1)\n    vol = df.groupby('time_10s')['total_bid_volume'].sum().reset_index(name='volume')\n\n    ohlcv = ohlcv.merge(vol, on='time_10s', how='left')\n\n    #Calculating log returns from close price using the formula\n    #Using 3 rolling windows each of size 10s to get short term volatility\n    ohlcv['log_return'] = np.log(ohlcv['close'] / ohlcv['close'].shift(1)).fillna(0)\n    ohlcv['rolling_vol_30'] = ohlcv['log_return'].rolling(window=3, min_periods=1).std().fillna(0)  \n\n    #Calculating spread between the highest and lowest bid prices in each row\n    bid_price_cols = [f'bid_price{i}' for i in range(1,5) if f'bid_price{i}' in df.columns]\n    df['spread'] = df[bid_price_cols].max(axis=1) - df[bid_price_cols].min(axis=1)\n    \n    #Aggregating the mean spread per 10s\n    spread_agg = df.groupby('time_10s')['spread'].mean().reset_index(name='avg_spread')\n    ohlcv = ohlcv.merge(spread_agg, on='time_10s', how='left')\n\n    if len(bid_volume_cols) >= 4:\n        \n        #Measures imbalance between top 2 vs next 2 bid volumes\n        top2 = df[bid_volume_cols[:2]].sum(axis=1)\n        next2 = df[bid_volume_cols[2:4]].sum(axis=1)\n        \n        #Normalizes the difference between the total volume\n        df['depth_imbalance'] = (top2 - next2) / (top2 + next2 + 1e-9)\n\n        #Aggregating per 10s\n        depth_imbalance_agg = df.groupby('time_10s')['depth_imbalance'].mean().reset_index(name='avg_depth_imbalance')\n        ohlcv = ohlcv.merge(depth_imbalance_agg, on='time_10s', how='left')\n    else:\n        ohlcv['avg_depth_imbalance'] = 0.0\n\n   \n    ohlcv['global_avg_mid_price'] = np.nan\n\n    #Taking the global_labels file and shifting it backwards by 10s such that labels align with 10s earlier\n    global_labels_shifted = global_labels.copy()\n    global_labels_shifted['timestamp_shifted'] = global_labels_shifted['timestamp'] - pd.Timedelta(seconds=10)\n    label_map = global_labels_shifted.set_index('timestamp_shifted')['labels'].to_dict()\n    ohlcv['label_t10'] = ohlcv['time_10s'].map(label_map)\n\n    #Returning the final engineered feature\n    return ohlcv","metadata":{"trusted":true,"execution":{"execution_failed":"2025-08-13T13:44:10.531Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nfeature_dfs = {}\n\nfor coin in coins:\n    print(f\"Processing features for {coin} ...\")\n    \n    #Reading the train and test csv files\n    train_path = os.path.join(TRAIN_DIR, f\"{coin}.csv\")\n    df_train = pd.read_csv(train_path)\n\n    #Running OHLCV on the Dataframe along with global_labels as input and storing it in a dict with coin as key\n    ohlcv_features = feature_engineering_coin(df_train, global_labels)\n    feature_dfs[coin] = ohlcv_features\n\n#Taking only the close price of each engineered coin and put them in Dataframe whose index is 'time_10s'\nall_coins_ohlcv = pd.concat([df.set_index('time_10s')[['close']] for df in feature_dfs.values()], axis=1)\nall_coins_ohlcv.columns = feature_dfs.keys()\n\n#Calculating the global_avg_mid_price by taking the mean of all close price\nglobal_avg_mid_price = all_coins_ohlcv.mean(axis=1).reset_index(name='global_avg_mid_price')\n\n#Repeating the process for all coins(BTC,ETH,DOGE etc.) ie. looping through all coins\nfor coin in coins:\n    df = feature_dfs[coin]\n    df = df.merge(global_avg_mid_price, on='time_10s', how='left')\n    feature_dfs[coin] = df\n\nprint(\"Feature engineering done for all coins.\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-08-13T13:44:10.531Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#All neccessary imports\nimport os\nimport numpy as np\nimport pandas as pd\nimport lightgbm as lgb\nfrom sklearn.model_selection import TimeSeriesSplit\nfrom scipy.stats import pearsonr\n\n#Fixed random SEED to 42\nSEED = 42\nnp.random.seed(SEED)\nTRAIN_DIR = \"/kaggle/input/gq-implied-volatility-forecasting/train\"\nTEST_DIR = \"/kaggle/input/gq-implied-volatility-forecasting/test\"\nOUT_DIR = \"/kaggle/working/submissions\"\nTSCV_SPLITS = 5\nos.makedirs(OUT_DIR, exist_ok=True)\n\n#Function for calculating pearson correlation\ndef pearson_corr(y_true, y_pred):\n    return pearsonr(y_true, y_pred)[0]\n\ncoins = sorted([f.replace(\".csv\", \"\") for f in os.listdir(TRAIN_DIR) if f.endswith(\".csv\")])\n\n#Creating volatality from mid_price changes using a rolling winndow of 10\n#Creating our target which is shifted by 10s later\ndef create_volatility_proxy(df, window=10):\n    df = df.copy\n    df['mid_price'] = pd.to_numeric(df['mid_price'], errors='coerce').ffill().bfill()\n    df['log_price'] = np.log(df['mid_price'])\n    df['log_ret'] = df['log_price'].diff()\n    df['vol_proxy'] = df['log_ret'].rolling(window).std().fillna(0)\n    return df\n\n#This is our feature_engineering step    \ndef feature_engineering(df):\n    df = df.copy()\n    for col in df.columns:\n        if 'price' in col or 'volume' in col:\n            df[col] = pd.to_numeric(df[col], errors='coerce').ffill().bfill()\n\n    #Calculating the mid_price as bid_price/ask_price\n    df['mid_price'] = (df['bid_price1'] + df['ask_price1']) / 2\n    \n    #Calculating the weighted_mid\n    df['weighted_mid'] = (\n        df['bid_price1'] * df['bid_volume1'] + \n        df['ask_price1'] * df['ask_volume1']\n    ) / (df['bid_volume1'] + df['ask_volume1'] + 1e-9)\n\n    #Calculating the spread as ask_price-bid_price\n    df['spread'] = df['ask_price1'] - df['bid_price1']\n    df['spread_ratio'] = df['spread'] / df['mid_price']\n\n    #Looping from 1 to 4(ie. from bid_price1 to bid_price4 and ask_price1 to ask_price4)\n    for i in range(1, 4):\n        if f'bid_price{i}' in df.columns and f'ask_price{i}' in df.columns:\n            df[f'price_imbalance_{i}'] = df[f'bid_price{i}'] / (df[f'ask_price{i}'] + 1e-9)\n            df[f'volume_imbalance_{i}'] = df[f'bid_volume{i}'] / (df[f'ask_volume{i}'] + 1e-9)\n\n    #Taking multiple volatality windows ie. 5,10,30\n    df = create_volatility_proxy(df)\n    for w in [5, 10, 30]:\n        df[f'vol_{w}'] = df['log_ret'].rolling(w).std().fillna(0)\n    \n    return df\n\nsubmission_list = []\n\n#Looping over each coin\nfor coin in coins:\n    print(f\"\\n=== Processing {coin} ===\")\n    \n    train_df = pd.read_csv(os.path.join(TRAIN_DIR, f\"{coin}.csv\"))\n    test_df = pd.read_csv(os.path.join(TEST_DIR, f\"{coin}.csv\"))\n    \n    train_df['timestamp'] = pd.to_datetime(train_df['timestamp'], errors='coerce')\n    test_df['timestamp'] = pd.to_datetime(test_df['timestamp'], errors='coerce')\n    train_df = train_df.dropna(subset=['timestamp']).sort_values('timestamp')\n    test_df = test_df.dropna(subset=['timestamp']).sort_values('timestamp')\n    \n    train_df = feature_engineering(train_df)\n    test_df = feature_engineering(test_df)\n    \n    #Creating our target variable and predict future volatility ahead of 10s\n    train_df['target'] = train_df['vol_proxy'].shift(-10)\n    train_df = train_df.dropna(subset=['target'])\n\n    #Excluding columns such as 'timestamp','target' etc. ensuring only numerical values\n    exclude_cols = ['timestamp', 'target', 'vol_proxy', 'log_price', 'log_ret']\n    feature_cols = [c for c in train_df.columns \n                   if c not in exclude_cols \n                   and c in test_df.columns\n                   and pd.api.types.is_numeric_dtype(train_df[c])]\n\n    #If numeric features not included then print and skip otherwise continue the loop\n    if not feature_cols:\n        print(f\"  No valid features for {coin}, skipping...\")\n        continue\n        \n    X_train = train_df[feature_cols].fillna(0)\n    y_train = train_df['target']\n    X_test = test_df[feature_cols].fillna(0)\n\n    models = []\n    \n    #Initialising time series cross validation\n    tscv = TimeSeriesSplit(n_splits=TSCV_SPLITS)\n\n    #Splitting into each fold(ie. 5)\n    for fold, (train_idx, val_idx) in enumerate(tscv.split(X_train)):\n        print(f\"  Fold {fold+1}/{TSCV_SPLITS}\")\n        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n        y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n\n        #Training our LightBGM model with leaves=31,learning rate=0.05,estimators=1000,SEED=42 and fold=5\n        model = lgb.LGBMRegressor(\n            objective='regression',\n            num_leaves=31,\n            learning_rate=0.05,\n            n_estimators=1000,\n            random_state=SEED + fold\n        )\n\n        #Fitting the model on our training and validation set using 'rmse' as evaluation metrics and early stopping as 50\n        model.fit(\n            X_tr, y_tr,\n            eval_set=[(X_val, y_val)],\n            eval_metric='rmse',\n            callbacks=[\n                lgb.early_stopping(50),\n                lgb.log_evaluation(100)\n            ]\n        )\n\n        #Appending our model to the models list\n        models.append(model)\n\n        #predicting the model on X_val(validation set)\n        val_pred = model.predict(X_val)\n        print(f\"   Pearson: {pearson_corr(y_val, val_pred):.4f}\")\n\n    #Averaging(taking mean of the model predictions on our test set) across all folds\n    test_preds = np.mean([model.predict(X_test) for model in models], axis=0)\n\n    #Saving per coin and final submission\n    coin_sub = pd.DataFrame({\n        'timestamp': test_df['timestamp'],\n        'predicted': test_preds\n    })\n    submission_list.append(coin_sub)\n    \n    coin_path = os.path.join(OUT_DIR, f\"{coin}_submission.csv\")\n    coin_sub.to_csv(coin_path, index=False)\n    print(f\"Saved {coin} predictions to {coin_path}\")\n\n#Concatenating to the final submission_list group by sorted timestamp\n#Joining the final_path to submission.csv\nif submission_list:\n    final_submission = pd.concat(submission_list).sort_values('timestamp')\n    final_path = os.path.join(OUT_DIR, \"submission.csv\")\n    final_submission.to_csv(final_path, index=False)\n    print(f\"\\nFinal submission saved to {final_path}\")\nelse:\n    print(\"No submissions generated\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-08-13T13:44:10.531Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport lightgbm as lgb\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import TimeSeriesSplit\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nfrom scipy.stats import pearsonr\n\n#Initialising SEED value to 42, TSCV_splits=5\nSEED = 42\nnp.random.seed(SEED)\nTRAIN_DIR = \"/kaggle/input/gq-implied-volatility-forecasting/train\"\nTEST_DIR = \"/kaggle/input/gq-implied-volatility-forecasting/test\"\nOUT_DIR = \"/kaggle/working/submissions\"\nTSCV_SPLITS = 5\nos.makedirs(OUT_DIR, exist_ok=True)\n\n#Calculating pearson correlation\ndef pearson_corr(y_true, y_pred):\n    return pearsonr(y_true, y_pred)[0]\n\n#Evaluating model using pearson_corr,mse,r2,rmse,mae\ndef evaluate_model(y_true, y_pred, model_name=\"Model\"):\n    mse = mean_squared_error(y_true, y_pred)\n    rmse = np.sqrt(mse)\n    mae = mean_absolute_error(y_true, y_pred)\n    r2 = r2_score(y_true, y_pred)\n    corr = pearson_corr(y_true, y_pred)\n    \n    print(f\"\\n{model_name} Evaluation:\")\n    print(f\"MSE: {mse:.4f}\")\n    print(f\"RMSE: {rmse:.4f}\")\n    print(f\"MAE: {mae:.4f}\")\n    print(f\"R²: {r2:.4f}\")\n    print(f\"Pearson Correlation: {corr:.4f}\")\n\n    #Plotting the graphs(Actual Volatility vs Predicted Volatility)\n    #Plotting scatterplot\n    plt.figure(figsize=(10, 6))\n    sns.scatterplot(x=y_true, y=y_pred, alpha=0.6)\n    plt.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'r--')\n    plt.xlabel('Actual Volatility')\n    plt.ylabel('Predicted Volatility')\n    plt.title(f'{model_name} - Predicted vs Actual Volatility')\n    plt.show()\n\n    #Calculating errors as true-predicted using 30 bins\n    #Finally plotting the figure and title as 'Prediction Error'\n    errors = y_true - y_pred\n    plt.figure(figsize=(10, 6))\n    sns.histplot(errors, kde=True, bins=30)\n    plt.xlabel('Prediction Error')\n    plt.title(f'{model_name} - Error Distribution')\n    plt.show()\n\n    #Returning metrics(mse,rmse,mae,r2,corr)\n    return {'mse': mse, 'rmse': rmse, 'mae': mae, 'r2': r2, 'corr': corr}\n\n#Plotting time_series_forecasting\n#Plotting predicted vs actual volatility over time\ndef plot_time_series_forecast(dates, y_true, y_pred, model_name=\"Model\"):\n    plt.figure(figsize=(14, 6))\n    plt.plot(dates, y_true, label='Actual Volatility')\n    plt.plot(dates, y_pred, label='Predicted Volatility', alpha=0.7)\n    plt.xlabel('Date')\n    plt.ylabel('Implied Volatility')\n    plt.title(f'{model_name} - Actual vs Predicted Volatility Over Time')\n    plt.legend()\n    plt.xticks(rotation=45)\n    plt.tight_layout()\n    plt.show()\n\n#Calculates directional_accuracy(% of time model correctly predicts the correct movement)\ndef directional_accuracy(y_true, y_pred):\n    true_direction = np.sign(np.diff(y_true))\n    pred_direction = np.sign(np.diff(y_pred))\n    return np.mean(true_direction == pred_direction) * 100\n\n#Creating volatality from mid_price changes using a rolling winndow of 10\n#Creating our target which is shifted by 10s later\ndef create_volatility_proxy(df, window=10):\n    df = df.copy()\n    df['mid_price'] = pd.to_numeric(df['mid_price'], errors='coerce').ffill().bfill()\n    df['log_price'] = np.log(df['mid_price'])\n    df['log_ret'] = df['log_price'].diff()\n    df['vol_proxy'] = df['log_ret'].rolling(window).std().fillna(0)\n    return df\n\n#This is our feature_engineering step\ndef feature_engineering(df):\n    df = df.copy()\n    for col in df.columns:\n        if 'price' in col or 'volume' in col:\n            df[col] = pd.to_numeric(df[col], errors='coerce').ffill().bfill()\n\n    #Calculating the mid_price as bid_price/ask_price\n    df['mid_price'] = (df['bid_price1'] + df['ask_price1']) / 2\n\n    #Calculating the weighted_mid\n    df['weighted_mid'] = (\n        df['bid_price1'] * df['bid_volume1'] + \n        df['ask_price1'] * df['ask_volume1']\n    ) / (df['bid_volume1'] + df['ask_volume1'] + 1e-9)\n\n    #Calculating the spread as ask_price-bid_price\n    df['spread'] = df['ask_price1'] - df['bid_price1']\n    df['spread_ratio'] = df['spread'] / df['mid_price']\n\n    #Looping from 1 to 4(ie. from bid_price1 to bid_price4 and ask_price1 to ask_price4)\n    for i in range(1, 4):\n        if f'bid_price{i}' in df.columns and f'ask_price{i}' in df.columns:\n            df[f'price_imbalance_{i}'] = df[f'bid_price{i}'] / (df[f'ask_price{i}'] + 1e-9)\n            df[f'volume_imbalance_{i}'] = df[f'bid_volume{i}'] / (df[f'ask_volume{i}'] + 1e-9)\n    \n    df = create_volatility_proxy(df)\n\n    #Taking multiple volatality windows ie. 5,10,30\n    for w in [5, 10, 30]:\n        df[f'vol_{w}'] = df['log_ret'].rolling(w).std().fillna(0)\n    \n    return df\n\ncoins = sorted([f.replace(\".csv\", \"\") for f in os.listdir(TRAIN_DIR) if f.endswith(\".csv\")])\nsubmission_list = []\nall_metrics = []\n\n#Looping over each coin\nfor coin in coins:\n    print(f\"\\n=== Processing {coin} ===\")\n    train_df = pd.read_csv(os.path.join(TRAIN_DIR, f\"{coin}.csv\"))\n    test_df = pd.read_csv(os.path.join(TEST_DIR, f\"{coin}.csv\"))\n    \n    train_df['timestamp'] = pd.to_datetime(train_df['timestamp'], errors='coerce')\n    test_df['timestamp'] = pd.to_datetime(test_df['timestamp'], errors='coerce')\n    train_df = train_df.dropna(subset=['timestamp']).sort_values('timestamp')\n    test_df = test_df.dropna(subset=['timestamp']).sort_values('timestamp')\n\n    #Performing feature_engineering on training Dataframe and testing Dataframe\n    train_df = feature_engineering(train_df)\n    test_df = feature_engineering(test_df)\n\n    #Creating our target variable and predict future volatility ahead of 10s\n    train_df['target'] = train_df['vol_proxy'].shift(-10)\n    train_df = train_df.dropna(subset=['target'])\n\n    #Excluding columns such as 'timestamp','target' etc. ensuring only numerical values\n    exclude_cols = ['timestamp', 'target', 'vol_proxy', 'log_price', 'log_ret']\n    feature_cols = [c for c in train_df.columns \n                   if c not in exclude_cols \n                   and c in test_df.columns\n                   and pd.api.types.is_numeric_dtype(train_df[c])]\n\n    #If numeric features not included then print and skip otherwise continue the loop\n    if not feature_cols:\n        print(f\"  No valid features for {coin}, skipping...\")\n        continue\n        \n    X_train = train_df[feature_cols].fillna(0)\n    y_train = train_df['target']\n    X_test = test_df[feature_cols].fillna(0)\n\n    models = []\n    fold_metrics = []\n    \n    #Initialising time series cross validation\n    tscv = TimeSeriesSplit(n_splits=TSCV_SPLITS)\n\n    #Splitting into each fold(ie. 5)\n    for fold, (train_idx, val_idx) in enumerate(tscv.split(X_train)):\n        print(f\"  Fold {fold+1}/{TSCV_SPLITS}\")\n        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n        y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n\n        #Training our LightBGM model with leaves=31,learning rate=0.05,estimators=1000,SEED=42 and fold=5\n        model = lgb.LGBMRegressor(\n            objective='regression',\n            num_leaves=31,\n            learning_rate=0.05,\n            n_estimators=1000,\n            random_state=SEED + fold,\n            n_jobs=-1\n        )\n\n        #Fitting the model on our training and validation set using 'rmse' as evaluation metrics and early stopping as 50\n        model.fit(\n            X_tr, y_tr,\n            eval_set=[(X_val, y_val)],\n            eval_metric='rmse',\n            callbacks=[\n                lgb.early_stopping(50),\n                lgb.log_evaluation(100)\n            ]\n        )\n\n        #Appending our model to the models list\n        models.append(model)\n\n        #predicting the model on X_val(validation set)\n        val_pred = model.predict(X_val)\n        fold_metric = evaluate_model(y_val, val_pred, f\"{coin} - Fold {fold+1}\")\n        fold_metric['fold'] = fold+1\n        fold_metrics.append(fold_metric)\n\n    #Calculating avg_metrics(RMSE,MAE,R^2,Pearson) across each fold\n    fold_df = pd.DataFrame(fold_metrics)\n    avg_metrics = fold_df.mean().to_dict()\n    avg_metrics['coin'] = coin\n    all_metrics.append(avg_metrics)\n    \n    print(f\"\\n{coin} Average CV Performance:\")\n    print(f\"RMSE: {avg_metrics['rmse']:.4f}\")\n    print(f\"MAE: {avg_metrics['mae']:.4f}\")\n    print(f\"R²: {avg_metrics['r2']:.4f}\")\n    print(f\"Pearson: {avg_metrics['corr']:.4f}\")\n\n    #Plotting figures of the result obtained across each fold(ie. 1 to 5)\n    plt.figure(figsize=(10, 8))\n    lgb.plot_importance(models[0], max_num_features=20)\n    plt.title(f'{coin} - Feature Importance')\n    plt.show()\n\n    #Averaging(taking mean of the model predictions on our test set) across all folds\n    test_preds = np.mean([model.predict(X_test) for model in models], axis=0)\n    \n    last_val_pred = models[-1].predict(X_val)\n    evaluate_model(y_val, last_val_pred, f\"{coin} - Final Validation\")\n    plot_time_series_forecast(train_df.iloc[val_idx]['timestamp'], y_val, last_val_pred, f\"{coin} - Validation\")\n\n    #Saving per coin and final submission\n    coin_sub = pd.DataFrame({\n        'timestamp': test_df['timestamp'],\n        'predicted': test_preds\n    })\n    submission_list.append(coin_sub)\n    coin_path = os.path.join(OUT_DIR, f\"{coin}_submission.csv\")\n    coin_sub.to_csv(coin_path, index=False)\n    print(f\"Saved {coin} predictions to {coin_path}\")\n\n#Concatenating to the final submission_list group by sorted timestamp\n#Joining the final_path to submission.csv\n#Simillarly concatenating final results(plots, metrices) and saving as performance_metrics.csv\n#Finally printing overall performance of each coin\nif submission_list:\n    final_submission = pd.concat(submission_list).sort_values('timestamp')\n    final_path = os.path.join(OUT_DIR, \"submission.csv\")\n    final_submission.to_csv(final_path, index=False)\n    print(f\"\\nFinal submission saved to {final_path}\")\n    \n    metrics_df = pd.DataFrame(all_metrics)\n    metrics_path = os.path.join(OUT_DIR, \"performance_metrics.csv\")\n    metrics_df.to_csv(metrics_path, index=False)\n    print(f\"Performance metrics saved to {metrics_path}\")\n    \n    print(\"\\nOverall Performance Across All Coins:\")\n    print(metrics_df[['coin', 'rmse', 'mae', 'r2', 'corr']].to_string(index=False))\nelse:\n    print(\"No submissions generated\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-08-13T13:44:10.531Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":" ","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}